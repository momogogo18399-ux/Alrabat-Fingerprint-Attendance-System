"""
Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø­Ø³Ù† 2.0
- Ù…Ø²Ø§Ù…Ù†Ø© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø§ØªØ¬Ø§Ù‡ (Real-time)
- Ø¥Ø´Ø¹Ø§Ø±Ø§Øª ÙÙˆØ±ÙŠØ© Ù„Ù„ØªØºÙŠÙŠØ±Ø§Øª
- ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±
- Ù†Ø¸Ø§Ù… Queue Ø°ÙƒÙŠ Ù„Ù„Ù…Ø²Ø§Ù…Ù†Ø©
"""

import os
import logging
import threading
import time
import queue
from typing import Dict, Any, List, Optional
from datetime import datetime
import json
import asyncio
from concurrent.futures import ThreadPoolExecutor

from .database_manager import DatabaseManager
from .supabase_manager import SupabaseManager

class EnhancedHybridManager:
    """
    Ù†Ø¸Ø§Ù… Ù…Ø²Ø§Ù…Ù†Ø© Ù…Ø­Ø³Ù† Ù…Ø¹ Real-time subscriptions
    """
    
    def __init__(self, local_db_path: str, supabase_url: str = None, supabase_key: str = None):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†"""
        # ØªØ¹ÙŠÙŠÙ† Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø©
        os.environ['SQLITE_FILE'] = os.path.basename(local_db_path)
        
        # ØªÙ‡ÙŠØ¦Ø© Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self.local_db = DatabaseManager()
        self.supabase_manager = None
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger('EnhancedHybrid')
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©
        self.supabase_enabled = False
        self.sync_queue = queue.Queue()
        self.executor = ThreadPoolExecutor(max_workers=3)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Real-time subscriptions
        self.subscriptions = {}
        self.last_sync_time = datetime.now()
        
        # Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©
        self.sync_stats = {
            'operations_count': 0,
            'successful_operations': 0,
            'failed_operations': 0,
            'last_operation': None
        }
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©
        self._setup_pending_changes_table()
        
        # Ù…Ø²Ø§Ù…Ù†Ø© Ø£ÙˆÙ„ÙŠØ© Ù…Ø¹ Ø³ÙˆØ¨Ø§Ø¨ÙŠØ³
        if supabase_url and supabase_key:
            self._initial_supabase_sync(supabase_url, supabase_key)
        else:
            self.logger.info("ğŸš« No Supabase credentials - running in local-only mode")
    
    def _setup_pending_changes_table(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©"""
        try:
            self.local_db._execute_query_with_commit("""
                CREATE TABLE IF NOT EXISTS pending_changes (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    table_name TEXT NOT NULL,
                    operation TEXT NOT NULL,
                    record_id TEXT NOT NULL,
                    data TEXT,
                    retry_count INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_attempt TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Add ÙÙ‡Ø±Ø³ Ù„Ù„Ø£Ø¯Ø§Ø¡
            self.local_db._execute_query_with_commit("""
                CREATE INDEX IF NOT EXISTS idx_pending_changes_created 
                ON pending_changes(created_at)
            """)
            
            self.logger.info("âœ… Enhanced pending changes table ready")
        except Exception as e:
            self.logger.error(f"âŒ Error setting up pending changes: {e}")
    
    def _initial_supabase_sync(self, supabase_url: str, supabase_key: str):
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø£ÙˆÙ„ÙŠØ© Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ Ø³ÙˆØ¨Ø§Ø¨ÙŠØ³"""
        try:
            self.logger.info("ğŸ”„ Enhanced initial sync with Supabase...")
            
            # ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø³ÙˆØ¨Ø§Ø¨ÙŠØ³
            self.supabase_manager = SupabaseManager()
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø­Ø³Ù†Ø©
            self._download_all_data_enhanced()
            
            # ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©
            self.supabase_enabled = True
            self.logger.info("âœ… Enhanced initial sync completed")
            
            # Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†
            self._start_enhanced_sync_system()
            
        except Exception as e:
            self.logger.error(f"âŒ Error during enhanced sync: {e}")
    
    def _download_all_data_enhanced(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø­Ø³Ù†Ø© ÙˆÙ…ØªÙˆØ§Ø²ÙŠØ©"""
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… ThreadPoolExecutor Ù„Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©
            futures = []
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†
            futures.append(
                self.executor.submit(self._sync_employees)
            )
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
            futures.append(
                self.executor.submit(self._sync_users)
            )
            
            # ØªØ­Ù…ÙŠÙ„ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø­Ø¶ÙˆØ±
            futures.append(
                self.executor.submit(self._sync_attendance)
            )
            
            # Ø§Ù†ØªØ¸Ø§Ø± Ø§ÙƒØªÙ…Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª
            for future in futures:
                future.result()
            
            self.logger.info("âœ… Enhanced parallel data download completed")
            
        except Exception as e:
            self.logger.error(f"âŒ Error in enhanced data download: {e}")
    
    def _sync_employees(self):
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†"""
        try:
            employees = self.supabase_manager.get_all_employees()
            new_count = 0
            updated_count = 0
            
            for emp in employees:
                try:
                    existing = self.local_db.get_employee_by_code(emp.get('employee_code'))
                    
                    emp_data = {
                        'employee_code': emp.get('employee_code') or f"EMP_{emp.get('id', 'XXX')}",
                        'name': emp.get('name') or 'Unknown',
                        'job_title': emp.get('job_title') or 'Unknown',
                        'department': emp.get('department') or 'Unknown',
                        'phone_number': emp.get('phone_number') or f"PHONE_{emp.get('id', 'UNK')}",
                        'qr_code': emp.get('qr_code', '')
                    }
                    
                    if existing:
                        if self.local_db.update_employee(existing['id'], emp_data):
                            updated_count += 1
                    else:
                        if self.local_db.add_employee(emp_data):
                            new_count += 1
                            
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Skipping employee {emp.get('name', 'Unknown')}: {e}")
            
            self.logger.info(f"ğŸ‘¥ Employees: {new_count} new, {updated_count} updated")
            
        except Exception as e:
            self.logger.error(f"âŒ Error syncing employees: {e}")
    
    def _sync_users(self):
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"""
        try:
            users = self.supabase_manager.get_all_users()
            count = 0
            
            for user in users:
                try:
                    if not self.local_db.get_user_by_username(user.get('username')):
                        user_data = {
                            'username': user.get('username'),
                            'password': user.get('password', 'default123'),
                            'role': user.get('role', 'user')
                        }
                        if self.local_db.add_user(user_data):
                            count += 1
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Failed to sync user {user.get('username')}: {e}")
            
            self.logger.info(f"ğŸ‘¤ Users: {count} synced")
            
        except Exception as e:
            self.logger.error(f"âŒ Error syncing users: {e}")
    
    def _sync_attendance(self):
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø­Ø¶ÙˆØ±"""
        try:
            attendance_records = self.supabase_manager.get_all_attendance()
            count = 0
            
            for record in attendance_records:
                try:
                    employee = self.local_db.get_employee_by_code(record.get('employee_code'))
                    if employee:
                        check_time = record.get('check_time') or record.get('check_in') or record.get('check_out') or datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        
                        attendance_data = {
                            'employee_id': str(employee['id']),
                            'check_time': check_time,
                            'date': record.get('date', datetime.now().strftime('%Y-%m-%d')),
                            'type': record.get('type', 'Check-In'),
                            'notes': record.get('notes', '')
                        }
                        
                        if self.local_db.add_attendance_record(attendance_data):
                            count += 1
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Failed to sync attendance record: {e}")
            
            self.logger.info(f"ğŸ“… Attendance: {count} records synced")
            
        except Exception as e:
            self.logger.error(f"âŒ Error syncing attendance: {e}")
    
    def _start_enhanced_sync_system(self):
        """Ø¨Ø¯Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø­Ø³Ù†"""
        if not self.supabase_enabled:
            return
        
        # Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ±
        self._start_queue_processor()
        
        # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© (ÙƒÙ†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©)
        self._start_auto_sync()
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯Ø¡ Real-time subscriptions
        self._start_realtime_subscriptions()
        
        self.logger.info("ğŸš€ Enhanced sync system started")
    
    def _start_queue_processor(self):
        """Ù…Ø¹Ø§Ù„Ø¬ Ø·Ø§Ø¨ÙˆØ± Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©"""
        def process_queue():
            self.logger.info("âš¡ Smart queue processor started")
            while self.supabase_enabled:
                try:
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù†Ø§ØµØ± ÙÙŠ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±
                    try:
                        sync_item = self.sync_queue.get(timeout=1)
                        self._process_sync_item(sync_item)
                        self.sync_queue.task_done()
                    except queue.Empty:
                        continue
                        
                except Exception as e:
                    self.logger.error(f"Queue processor error: {e}")
        
        queue_thread = threading.Thread(target=process_queue, daemon=True)
        queue_thread.start()
    
    def _start_auto_sync(self):
        """Ù…Ø²Ø§Ù…Ù†Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ù…Ø­Ø³Ù†Ø©"""
        def auto_sync():
            self.logger.info("ğŸ”„ Enhanced auto-sync started (every 30 seconds)")
            sync_count = 0
            while self.supabase_enabled:
                try:
                    time.sleep(30)  # ÙƒÙ„ 30 Ø«Ø§Ù†ÙŠØ© (Ø£Ù‚Ù„ ØªÙƒØ±Ø§Ø±Ø§Ù‹)
                    self._sync_pending_changes_enhanced()
                    
                    # ØªÙ†Ø¸ÙŠÙ ÙƒÙ„ 5 Ø¯Ù‚Ø§Ø¦Ù‚ (10 Ø¯ÙˆØ±Ø§Øª Ã— 30 Ø«Ø§Ù†ÙŠØ©)
                    sync_count += 1
                    if sync_count >= 10:
                        self.cleanup_failed_changes()
                        sync_count = 0
                        
                except Exception as e:
                    self.logger.error(f"Auto-sync error: {e}")
        
        sync_thread = threading.Thread(target=auto_sync, daemon=True)
        sync_thread.start()
    
    def _start_realtime_subscriptions(self):
        """Ø¨Ø¯Ø¡ Real-time subscriptions (ØªØ¬Ø±ÙŠØ¨ÙŠ)"""
        try:
            # Ù‡Ø°Ø§ ØªØ¬Ø±ÙŠØ¨ÙŠ - ÙŠØ­ØªØ§Ø¬ Ù…ÙƒØªØ¨Ø© supabase-realtime
            self.logger.info("ğŸ”´ Real-time subscriptions (experimental)")
            # ÙŠÙ…ÙƒÙ† Add Real-time subscriptions Ù‡Ù†Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹
        except Exception as e:
            self.logger.warning(f"âš ï¸ Real-time subscriptions not available: {e}")
    
    def _record_change_enhanced(self, table_name: str, operation: str, record_id: str, data: Dict[str, Any] = None):
        """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØºÙŠÙŠØ± Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø­Ø³Ù†Ø©"""
        if not self.supabase_enabled:
            return
        
        try:
            # Add Ù„Ù„Ø·Ø§Ø¨ÙˆØ± Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
            sync_item = {
                'table_name': table_name,
                'operation': operation,
                'record_id': record_id,
                'data': data,
                'timestamp': datetime.now().isoformat()
            }
            
            self.sync_queue.put(sync_item)
            
            # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            data_json = json.dumps(data) if data else '{}'
            self.local_db._execute_query_with_commit(
                "INSERT INTO pending_changes (table_name, operation, record_id, data) VALUES (?, ?, ?, ?)",
                (table_name, operation, record_id, data_json)
            )
            
            self.logger.info(f"ğŸ“ Enhanced change recorded: {operation} {table_name}:{record_id}")
            
        except Exception as e:
            self.logger.error(f"Error recording enhanced change: {e}")
    
    def _process_sync_item(self, sync_item):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ù†ØµØ± Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©"""
        try:
            table_name = sync_item['table_name']
            operation = sync_item['operation']
            record_id = sync_item['record_id']
            data = sync_item['data']
            
            success = False
            
            if operation == 'INSERT':
                success = self._sync_insert_enhanced(table_name, data)
            elif operation == 'UPDATE':
                success = self._sync_update_enhanced(table_name, record_id, data)
            elif operation == 'DELETE':
                success = self._sync_delete_enhanced(table_name, record_id)
            
            # Update Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            self.sync_stats['operations_count'] += 1
            self.sync_stats['last_operation'] = f"{operation} {table_name}:{record_id}"
            
            if success:
                self.sync_stats['successful_operations'] += 1
                self.logger.info(f"âœ… Enhanced sync success: {operation} {table_name}:{record_id}")
            else:
                self.sync_stats['failed_operations'] += 1
                self.logger.error(f"âŒ Enhanced sync failed: {operation} {table_name}:{record_id}")
                
        except Exception as e:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù„ØªÙƒØ±Ø§Ø±
            if "duplicate key" in str(e) or "23505" in str(e):
                self.sync_stats['successful_operations'] += 1
                self.logger.warning(f"âš ï¸ Duplicate conflict resolved for {operation} {table_name}:{record_id}")
            else:
                self.sync_stats['failed_operations'] += 1
                self.logger.error(f"âŒ Error processing sync item: {e}")
    
    def _sync_insert_enhanced(self, table_name: str, data: Dict[str, Any]) -> bool:
        """Ø¥Ø¯Ø±Ø§Ø¬ Ù…Ø­Ø³Ù† Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±"""
        try:
            if table_name == 'employees':
                try:
                    result = self.supabase_manager.add_employee(data)
                    return bool(result)
                except Exception as e:
                    if "duplicate key" in str(e) or "23505" in str(e):
                        self.logger.warning(f"âš ï¸ Employee already exists in Supabase: {data.get('employee_code')} - ignoring")
                        return True  # Ù†Ø¹ØªØ¨Ø± Ù‡Ø°Ø§ Ù†Ø¬Ø§Ø­ Ù„Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
                    raise e
                    
            elif table_name == 'users':
                try:
                    result = self.supabase_manager.add_user(data)
                    return bool(result)
                except Exception as e:
                    if "duplicate key" in str(e) or "23505" in str(e):
                        self.logger.warning(f"âš ï¸ User already exists in Supabase: {data.get('username')} - ignoring")
                        return True
                    raise e
                    
            elif table_name == 'attendance':
                return bool(self.supabase_manager.record_attendance(data))
            return False
            
        except Exception as e:
            if "duplicate key" in str(e) or "23505" in str(e):
                self.logger.warning(f"âš ï¸ Duplicate key ignored for {table_name}: {e}")
                return True
            self.logger.error(f"Enhanced insert error: {e}")
            return False
    
    def _sync_update_enhanced(self, table_name: str, record_id: str, data: Dict[str, Any]) -> bool:
        """Update Ù…Ø­Ø³Ù† Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±"""
        try:
            if table_name == 'employees':
                try:
                    return self.supabase_manager.update_employee(record_id, data)
                except Exception as e:
                    if "duplicate key" in str(e) or "23505" in str(e):
                        self.logger.warning(f"âš ï¸ Employee update conflict: {data.get('employee_code')} - data already exists")
                        return True  # Ù†Ø¹ØªØ¨Ø± Ù‡Ø°Ø§ Ù†Ø¬Ø§Ø­ Ù„Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
                    raise e
                    
            elif table_name == 'users':
                try:
                    return self.supabase_manager.update_user(record_id, data)
                except Exception as e:
                    if "duplicate key" in str(e) or "23505" in str(e):
                        self.logger.warning(f"âš ï¸ User update conflict: {data.get('username')} - data already exists")
                        return True
                    raise e
                    
            elif table_name == 'attendance':
                return self.supabase_manager.update_attendance(record_id, data)
            return False
            
        except Exception as e:
            if "duplicate key" in str(e) or "23505" in str(e):
                self.logger.warning(f"âš ï¸ Update conflict ignored for {table_name}: {e}")
                return True
            self.logger.error(f"Enhanced update error: {e}")
            return False
    
    def _sync_delete_enhanced(self, table_name: str, record_id: str) -> bool:
        """Delete Ù…Ø­Ø³Ù†"""
        try:
            if table_name == 'employees':
                return self.supabase_manager.delete_employee(record_id)
            elif table_name == 'users':
                return self.supabase_manager.delete_user(record_id)
            elif table_name == 'attendance':
                return self.supabase_manager.delete_attendance(record_id)
            return False
        except Exception as e:
            self.logger.error(f"Enhanced delete error: {e}")
            return False
    
    def _sync_pending_changes_enhanced(self):
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø­Ø³Ù†Ø©"""
        if not self.supabase_enabled:
            return
        
        try:
            # Ø¬Ù„Ø¨ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
            changes = self.local_db._execute_query(
                """SELECT * FROM pending_changes 
                   WHERE retry_count < 3 
                   ORDER BY created_at ASC 
                   LIMIT 50""",
                fetch=True
            )
            
            if not changes:
                return
            
            self.logger.info(f"ğŸ”„ Processing {len(changes)} pending changes")
            
            for change in changes:
                try:
                    success = False
                    
                    if change['operation'] == 'INSERT':
                        data = json.loads(change['data'])
                        success = self._sync_insert_enhanced(change['table_name'], data)
                    elif change['operation'] == 'UPDATE':
                        data = json.loads(change['data'])
                        success = self._sync_update_enhanced(change['table_name'], change['record_id'], data)
                    elif change['operation'] == 'DELETE':
                        success = self._sync_delete_enhanced(change['table_name'], change['record_id'])
                    
                    if success:
                        # Delete Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ù†Ø§Ø¬Ø­
                        self.local_db._execute_query_with_commit(
                            "DELETE FROM pending_changes WHERE id = ?",
                            (change['id'],)
                        )
                        # Delete Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ù„Ù„Ø¹Ù†ØµØ± Ù†ÙØ³Ù‡
                        self.local_db._execute_query_with_commit(
                            "DELETE FROM pending_changes WHERE table_name = ? AND record_id = ? AND operation = ?",
                            (change['table_name'], change['record_id'], change['operation'])
                        )
                    else:
                        # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
                        self.local_db._execute_query_with_commit(
                            "UPDATE pending_changes SET retry_count = retry_count + 1, last_attempt = CURRENT_TIMESTAMP WHERE id = ?",
                            (change['id'],)
                        )
                        
                except Exception as e:
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù„ØªÙƒØ±Ø§Ø± ÙÙŠ Background sync
                    if "duplicate key" in str(e) or "23505" in str(e):
                        self.logger.warning(f"âš ï¸ Background sync: Duplicate key ignored for {change['operation']} {change['table_name']}:{change['record_id']}")
                        # Ø§Ø¹ØªØ¨Ø± Ù‡Ø°Ø§ Ù†Ø¬Ø§Ø­Ø§Ù‹ ÙˆØ§Delete Ø§Ù„ØªØºÙŠÙŠØ±
                        self.local_db._execute_query_with_commit(
                            "DELETE FROM pending_changes WHERE id = ?",
                            (change['id'],)
                        )
                        # Delete Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø£ÙŠØ¶Ø§Ù‹
                        self.local_db._execute_query_with_commit(
                            "DELETE FROM pending_changes WHERE table_name = ? AND record_id = ? AND operation = ?",
                            (change['table_name'], change['record_id'], change['operation'])
                        )
                    else:
                        self.logger.error(f"Error processing change {change['id']}: {e}")
                        # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ù„Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø£Ø®Ø±Ù‰
                        self.local_db._execute_query_with_commit(
                            "UPDATE pending_changes SET retry_count = retry_count + 1, last_attempt = CURRENT_TIMESTAMP WHERE id = ?",
                            (change['id'],)
                        )
                    
        except Exception as e:
            self.logger.error(f"Error in enhanced pending sync: {e}")
    
    # --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (ØªÙ…Ø±ÙŠØ± Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©) ---
    
    def add_employee(self, data):
        """Add Ù…ÙˆØ¸Ù Ù…Ø¹ Ù…Ø²Ø§Ù…Ù†Ø© Ù…Ø­Ø³Ù†Ø©"""
        result = self.local_db.add_employee(data)
        if result:
            self._record_change_enhanced('employees', 'INSERT', str(result), data)
        return result
    
    def update_employee(self, employee_id, employee_data):
        """Update employee Ù…Ø¹ Ù…Ø²Ø§Ù…Ù†Ø© Ù…Ø­Ø³Ù†Ø©"""
        result = self.local_db.update_employee(employee_id, employee_data)
        if result:
            self._record_change_enhanced('employees', 'UPDATE', str(employee_id), employee_data)
        return result
    
    def delete_employee(self, employee_id):
        """Delete Ù…ÙˆØ¸Ù Ù…Ø¹ Ù…Ø²Ø§Ù…Ù†Ø© Ù…Ø­Ø³Ù†Ø©"""
        result = self.local_db.delete_employee(employee_id)
        if result:
            self._record_change_enhanced('employees', 'DELETE', str(employee_id))
        return result
    
    def add_user(self, user_data):
        """Add Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ Ù…Ø²Ø§Ù…Ù†Ø© Ù…Ø­Ø³Ù†Ø©"""
        result = self.local_db.add_user(user_data)
        if result:
            self._record_change_enhanced('users', 'INSERT', str(result), user_data)
        return result
    
    def record_attendance(self, employee_id, attendance_type, location_id=None, notes=None):
        """ØªØ³Ø¬ÙŠÙ„ Ø­Ø¶ÙˆØ± Ù…Ø¹ Ù…Ø²Ø§Ù…Ù†Ø© Ù…Ø­Ø³Ù†Ø©"""
        result = self.local_db.record_attendance(employee_id, attendance_type, location_id, notes)
        if result:
            attendance_data = {
                'employee_id': employee_id,
                'type': attendance_type,
                'location_id': location_id,
                'notes': notes,
                'date': datetime.now().strftime('%Y-%m-%d'),
                'check_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            self._record_change_enhanced('attendance', 'INSERT', str(result), attendance_data)
        return result
    
    def force_full_sync(self):
        """Ø¥Ø¬Ø¨Ø§Ø± Ù…Ø²Ø§Ù…Ù†Ø© ÙƒØ§Ù…Ù„Ø©"""
        if not self.supabase_enabled:
            return False
        
        try:
            self.logger.info("ğŸ”„ Starting forced full sync...")
            self._download_all_data_enhanced()
            self._sync_pending_changes_enhanced()
            self.logger.info("âœ… Forced full sync completed")
            return True
        except Exception as e:
            self.logger.error(f"Forced sync error: {e}")
            return False
    
    def cleanup_failed_changes(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø© Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©"""
        try:
            # Delete Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„ØªÙŠ FailedØª Ø£ÙƒØ«Ø± Ù…Ù† 3 Ù…Ø±Ø§Øª ÙˆÙƒØ§Ù†Øª duplicate key
            self.local_db._execute_query_with_commit(
                "DELETE FROM pending_changes WHERE retry_count >= 3"
            )
            self.logger.info("ğŸ§¹ Cleaned up failed pending changes")
        except Exception as e:
            self.logger.error(f"Error cleaning failed changes: {e}")
    
    def get_sync_stats(self):
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©"""
        try:
            pending_count = self.local_db._execute_query(
                "SELECT COUNT(*) as count FROM pending_changes",
                fetch=True
            )[0]['count']
            
            failed_count = self.local_db._execute_query(
                "SELECT COUNT(*) as count FROM pending_changes WHERE retry_count >= 3",
                fetch=True
            )[0]['count']
            
            success_rate = 0
            if self.sync_stats['operations_count'] > 0:
                success_rate = (self.sync_stats['successful_operations'] / self.sync_stats['operations_count']) * 100
            
            return {
                'mode': 'Enhanced Hybrid 2.0',
                'supabase_enabled': self.supabase_enabled,
                'pending_changes': pending_count,
                'failed_changes': failed_count,
                'queue_size': self.sync_queue.qsize(),
                'last_sync': self.last_sync_time.isoformat(),
                'total_operations': self.sync_stats['operations_count'],
                'successful_operations': self.sync_stats['successful_operations'],
                'failed_operations': self.sync_stats['failed_operations'],
                'success_rate': f"{success_rate:.1f}%",
                'last_operation': self.sync_stats.get('last_operation', 'None')
            }
        except Exception as e:
            self.logger.error(f"Error getting sync stats: {e}")
            return {'error': str(e)}
    
    def print_sync_status(self):
        """Ø·Ø¨Ø§Ø¹Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©"""
        stats = self.get_sync_stats()
        if 'error' in stats:
            self.logger.error(f"ğŸ“Š Stats error: {stats['error']}")
            return
            
        self.logger.info("ğŸ“Š Enhanced Sync Status:")
        self.logger.info(f"   ğŸ”„ Mode: {stats['mode']}")
        self.logger.info(f"   ğŸŒ Supabase: {'âœ… Enabled' if stats['supabase_enabled'] else 'âŒ Disabled'}")
        self.logger.info(f"   ğŸ“Š Success Rate: {stats['success_rate']}")
        self.logger.info(f"   ğŸ“ Total Operations: {stats['total_operations']}")
        self.logger.info(f"   âœ… Successful: {stats['successful_operations']}")
        self.logger.info(f"   âŒ Failed: {stats['failed_operations']}")
        self.logger.info(f"   â³ Pending: {stats['pending_changes']}")
        self.logger.info(f"   ğŸ—ƒï¸ Queue Size: {stats['queue_size']}")
        self.logger.info(f"   ğŸ• Last Operation: {stats['last_operation']}")
    
    def cleanup_on_exit(self):
        """ØªÙ†Ø¸ÙŠÙ Ù…Ø­Ø³Ù† Ø¹Ù†Ø¯ Ø§Ù„Ø®Ø±ÙˆØ¬"""
        try:
            self.logger.info("ğŸ”„ Enhanced cleanup starting...")
            
            # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©
            self.supabase_enabled = False
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¢Ø®Ø± Ø§Ù„Ø¹Ù†Ø§ØµØ± ÙÙŠ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±
            while not self.sync_queue.empty():
                try:
                    sync_item = self.sync_queue.get_nowait()
                    self._process_sync_item(sync_item)
                except queue.Empty:
                    break
            
            # Close Ø§Ù„Ù€ executor
            self.executor.shutdown(wait=True)
            
            self.logger.info("âœ… Enhanced cleanup completed")
            
        except Exception as e:
            self.logger.error(f"Enhanced cleanup error: {e}")
    
    def __getattr__(self, name):
        """ØªÙ…Ø±ÙŠØ± Ø§Ù„Ø¯ÙˆØ§Ù„ ØºÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©"""
        if hasattr(self.local_db, name):
            return getattr(self.local_db, name)
        raise AttributeError(f"'{self.__class__.__name__}' object has no attribute '{name}'")
